import streamlit as st
from PIL import Image
import google.generativeai as genai
import time

# --- 1. ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="ê´€ìƒê°€ ì•„ì†”",
    page_icon="ğŸ§™â€â™‚ï¸",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# --- 2. [í•„ìˆ˜] ì¸ì•± ë¸Œë¼ìš°ì € ì°¨ë‹¨ ---
st.components.v1.html("""
<script>
    var userAgent = navigator.userAgent.toLowerCase();
    var isInApp = userAgent.indexOf("kakao") > -1 || userAgent.indexOf("instagram") > -1 || userAgent.indexOf("line") > -1;
    if (isInApp) {
        document.body.innerHTML = `
            <div style="position: fixed; top: 0; left: 0; width: 100%; height: 100%; background-color: #fff; z-index: 9999; display: flex; flex-direction: column; justify-content: center; align-items: center; text-align: center; font-family: sans-serif; padding: 20px;">
                <h1 style="color: #d32f2f;">â›”ï¸ ì ‘ì† ë¶ˆê°€</h1>
                <p>ì¹´ì¹´ì˜¤í†¡/ì¸ìŠ¤íƒ€ê·¸ë¨ì—ì„œëŠ” ì¹´ë©”ë¼ê°€ ì•ˆ ì—´ë¦¬ì˜¤.<br>ìš°ì¸¡ ìƒë‹¨ ì  3ê°œ(...)ë¥¼ ëˆŒëŸ¬ <b>[ë‹¤ë¥¸ ë¸Œë¼ìš°ì €ë¡œ ì—´ê¸°]</b>ë¥¼ í•˜ì‹œì˜¤.</p>
            </div>
        `;
    }
</script>
""", height=0)

# --- 3. ìŠ¤íƒ€ì¼ ê¾¸ë¯¸ê¸° ---
st.markdown("""
    <style>
    .stButton>button {
        width: 100%; margin-top: 10px; background-color: #7D5A5A; color: white; font-weight: bold; border-radius: 10px; padding: 12px;
    }
    div.row-widget.stRadio > div { flex-direction: row; justify-content: center; gap: 15px; }
    .main-header { text-align: center; font-family: 'Helvetica', sans-serif; color: #333; }
    </style>
    """, unsafe_allow_html=True)

# --- 4. API í‚¤ ì—°ê²° ---
try:
    genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])
except:
    st.error("ğŸš¨ API í‚¤ ì„¤ì •ì„ í™•ì¸í•˜ì‹œì˜¤.")
    st.stop()

# --- 5. [í•µì‹¬] ì¥êµ°ì‹  ìë™ ë¡œí…Œì´ì…˜ ì‹œìŠ¤í…œ ---
def get_all_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ì¥êµ°ì‹  ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    try:
        all_models = []
        for model_info in genai.list_models():
            if 'generateContent' in model_info.supported_generation_methods:
                all_models.append(model_info.name)
        return all_models
    except:
        # API í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ìˆ˜ë™ ë°±ì—… ë¦¬ìŠ¤íŠ¸
        return [
            'gemini-1.5-flash',
            'gemini-1.5-flash-latest',
            'gemini-1.5-pro',
            'gemini-1.5-pro-latest',
            'gemini-2.0-flash-exp',
            'models/gemini-1.5-flash',
            'models/gemini-1.5-pro'
        ]

def try_model_with_image(model_name, prompt, image):
    """íŠ¹ì • ì¥êµ°ì‹ ìœ¼ë¡œ ê´€ìƒ ì‹œë„"""
    try:
        model = genai.GenerativeModel(model_name)
        response = model.generate_content([prompt, image])
        return response, None  # ì„±ê³µ
    except Exception as e:
        error_msg = str(e)
        # 429 ì—ëŸ¬ (í• ë‹¹ëŸ‰ ì´ˆê³¼) ë˜ëŠ” ë‹¤ë¥¸ ì—ëŸ¬ ë°˜í™˜
        if "429" in error_msg or "quota" in error_msg.lower():
            return None, "quota_exceeded"
        elif "404" in error_msg or "not found" in error_msg.lower():
            return None, "model_not_found"
        else:
            return None, error_msg

# --- 6. ì„¸ì…˜ ì´ˆê¸°í™” ---
if 'final_image' not in st.session_state:
    st.session_state.final_image = None

# --- 7. í™”ë©´ êµ¬ì„± ---
st.markdown("<h1 class='main-header'>ğŸ§™â€â™‚ï¸ ê´€ìƒê°€ 'ì•„ì†”'</h1>", unsafe_allow_html=True)
st.write("---")

input_method = st.radio(
    "ì‚¬ì§„ ì¤€ë¹„ ë°©ì‹ì„ ì„ íƒí•˜ì‹œì˜¤:",
    ("ğŸ“¸ ì§ì ‘ ì´¬ì˜", "ğŸ“‚ ì•¨ë²” ì„ íƒ"),
    horizontal=True
)

if input_method == "ğŸ“¸ ì§ì ‘ ì´¬ì˜":
    camera_image = st.camera_input("ì´¬ì˜", label_visibility="collapsed")
    if camera_image: 
        st.session_state.final_image = camera_image
elif input_method == "ğŸ“‚ ì•¨ë²” ì„ íƒ":
    uploaded_file = st.file_uploader("ì—…ë¡œë“œ", type=['jpg', 'jpeg', 'png'], label_visibility="collapsed")
    if uploaded_file: 
        st.session_state.final_image = uploaded_file

# --- 8. ë¶„ì„ ë° ì‹¤í–‰ ë¡œì§ ---
if st.session_state.final_image:
    st.write("---")
    st.image(st.session_state.final_image, caption="ì„ íƒëœ ì–¼êµ´", use_container_width=True)

    if st.button("ğŸ”® ì•„ì†”ì—ê²Œ ê´€ìƒ ë¬»ê¸°"):
        try:
            progress_bar = st.progress(0)
            status_text = st.empty()

            # ---------------------------------------------------------
            # 1ë‹¨ê³„: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  ì¥êµ°ì‹  ëª…ë‹¨ ê°€ì ¸ì˜¤ê¸°
            # ---------------------------------------------------------
            status_text.markdown("### ğŸ“¡ ë‹¹ì§ ì„œëŠ” ì¥êµ°ì‹ ì„ ì°¾ëŠ” ì¤‘ì´ì˜¤...")
            progress_bar.progress(5)
            
            available_models = get_all_available_models()
            
            if not available_models:
                st.error("âš ï¸ ì¥êµ°ì‹  ëª…ë‹¨ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ì†Œ. ë„¤íŠ¸ì›Œí¬ë¥¼ í™•ì¸í•˜ì‹œì˜¤.")
                st.stop()

            # ---------------------------------------------------------
            # 2ë‹¨ê³„: ì–¼êµ´ ë¶€ìœ„ë³„ ë¶„ì„ ì• ë‹ˆë©”ì´ì…˜
            # ---------------------------------------------------------
            analysis_steps = [
                "1ë‹¨ê³„: ì´ë§ˆì˜ ë„“ì´ì™€ ì´ˆë…„ìš´ ì¸¡ì • ì¤‘...",
                "2ë‹¨ê³„: ëˆˆì¹ì˜ ê¸°ì„¸ì™€ í˜•ì œìš´ ë¶„ì„ ì¤‘...",
                "3ë‹¨ê³„: ì½”ì˜ ë†’ì´ì™€ ì¬ë¬¼ìš´ ê³„ì‚° ì¤‘...",
                "4ë‹¨ê³„: ì…ìˆ ì˜ ëª¨ì–‘ê³¼ ë§ë…„ìš´ í™•ì¸ ì¤‘...",
                "5ë‹¨ê³„: ì–¼êµ´ì˜ ì „ì²´ì ì¸ ì¡°í™”(ì˜¤í–‰) ë¶„ì„ ì¤‘..."
            ]
            
            for i, step in enumerate(analysis_steps):
                status_text.markdown(f"### ğŸ” {step}")
                progress_bar.progress(5 + (i + 1) * 15)
                time.sleep(1.0)

            # ---------------------------------------------------------
            # 3ë‹¨ê³„: ì¥êµ°ì‹  ìˆœì°¨ ì†Œí™˜ (í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ ìë™ êµì²´)
            # ---------------------------------------------------------
            prompt = """
            ë‹¹ì‹ ì˜ ì´ë¦„ì€ 'ì•„ì†”'ì…ë‹ˆë‹¤. ì¡°ì„  íŒ”ë„ì—ì„œ ê°€ì¥ ìš©í•œ ì „ì„¤ì ì¸ ê´€ìƒê°€ì…ë‹ˆë‹¤.
            ì´ ì‚¬ì§„ì˜ ì¸ë¬¼ì„ ë³´ê³  ë‹¤ìŒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ê´€ìƒì„ ì•„ì£¼ ìƒì„¸í•˜ê³  ì¬ë¯¸ìˆê²Œ ë´ì£¼ì„¸ìš”.
            ë§íˆ¬ëŠ” ìœ„ì—„ ìˆìœ¼ë©´ì„œë„ ì¹œê·¼í•œ ì‚¬ê·¹ í†¤("~í•˜ì˜¤", "~ì´ì˜¤")ì„ ì‚¬ìš©í•˜ì„¸ìš”.
            
            [ì•„ì†”ì˜ ê°ì •ì„œ]
            1. ğŸ­ ì¸ìƒ ì´í‰ (ì´ˆë…„, ì¤‘ë…„, ë§ë…„)
            2. ğŸ’° ì¬ë¬¼ìš´ (ê³³ê°„ì´ ì°° ìƒì¸ê°€?)
            3. â¤ï¸ ì—°ì•  ë° ì• ì •ìš´ (ë„í™”ì‚´ ìœ ë¬´)
            4. ğŸ€ ì•„ì†”ì˜ íŠ¹ë³„ ì²˜ë°© (ì¡°ì–¸)
            
            ì¬ë¯¸ìˆê²Œ íŒ©íŠ¸ í­ê²©ì„ ì„ì–´ì„œ ì‹ í†µë°©í†µí•˜ê²Œ ë§í•´ì£¼ì„¸ìš”.
            """
            
            image = Image.open(st.session_state.final_image)
            response = None
            successful_model = None
            tried_models = []
            
            for model_name in available_models:
                display_name = model_name.replace('models/', '').replace('gemini-', '').upper()
                
                status_text.markdown(f"### âš¡ **{display_name}** ì¥êµ°ì‹  ì†Œí™˜ ì¤‘...")
                progress_bar.progress(85)
                
                response, error = try_model_with_image(model_name, prompt, image)
                tried_models.append(model_name)
                
                if response is not None:
                    # âœ… ì„±ê³µ!
                    successful_model = display_name
                    break
                else:
                    # âŒ ì‹¤íŒ¨ - ë‹¤ìŒ ì¥êµ°ì‹ ìœ¼ë¡œ
                    if error == "quota_exceeded":
                        status_text.markdown(f"### ğŸ’¤ {display_name} ì¥êµ°ì‹ ì´ íœ´ì‹ ì¤‘ì´ì˜¤... ë‹¤ë¥¸ ì¥êµ°ì‹  ì°¾ëŠ” ì¤‘...")
                        time.sleep(0.8)
                    elif error == "model_not_found":
                        continue  # ì¡°ìš©íˆ ë‹¤ìŒìœ¼ë¡œ
                    else:
                        continue  # ê¸°íƒ€ ì—ëŸ¬ë„ ë‹¤ìŒìœ¼ë¡œ
            
            # ---------------------------------------------------------
            # 4ë‹¨ê³„: ê²°ê³¼ í™•ì¸
            # ---------------------------------------------------------
            if response is None:
                st.error("âš ï¸ ëª¨ë“  ì¥êµ°ì‹ ì´ íœ´ì‹ ì¤‘ì´ê±°ë‚˜ ì†Œí™˜í•  ìˆ˜ ì—†ì†Œ.")
                st.info(f"ğŸ’¡ ì‹œë„í•œ ì¥êµ°ì‹ : {len(tried_models)}ëª…")
                st.warning("ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì‹œê±°ë‚˜, ë‹¤ë¥¸ ì‹œê°„ëŒ€ì— ì°¾ì•„ì£¼ì‹œì˜¤.")
                st.stop()
            
            # ---------------------------------------------------------
            # 5ë‹¨ê³„: ì„±ê³µì ì¸ ê°ì •ì„œ ì¶œë ¥
            # ---------------------------------------------------------
            status_text.markdown(f"### âœ… **{successful_model}** ì¥êµ°ì‹ ì´ ê°ì •ì„œë¥¼ ì‘ì„±í–ˆì†Œ!")
            progress_bar.progress(100)
            time.sleep(1.0)
            
            progress_bar.empty()
            status_text.empty()
            
            st.write("---")
            st.subheader(f"ğŸ“œ ì•„ì†”ì˜ ê´€ìƒ í’€ì´ (by {successful_model} ì¥êµ°ì‹ )")
            st.markdown(response.text)
            st.balloons()

        except Exception as e:
            st.error(f"ì˜ˆê¸°ì¹˜ ëª»í•œ ì—ëŸ¬ê°€ ë‚¬ì†Œ. (ë‚´ìš©: {e})")
            st.info("ğŸ’¡ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜, ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì‹œì˜¤.")